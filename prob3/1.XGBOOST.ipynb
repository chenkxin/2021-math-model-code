{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9bb54771ab0e8de3f40d12e7f47d3c86fe58645b"
   },
   "source": [
    "# Hourly Time Series Forecasting using XGBoost\n",
    "\n",
    "[If you haven't already first check out my previous notebook forecasting on the same data using Prophet](https://www.kaggle.com/robikscube/hourly-time-series-forecasting-with-prophet)\n",
    "\n",
    "In this notebook we will walk through time series forecasting using XGBoost. The data we will be using is hourly energy consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/qiangzibro/2021-math-model-code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# set working directory to root \n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from common.io import load, load_tables, PLACES\n",
    "from common.utils import find_pollution_columns, POLLUTIONS, write_excel\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from prob1.aqi import compute_aqi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "# Linux上解决字体问题\n",
    "plt.rcParams['font.sans-serif']= ['Noto Serif CJK JP'] #显示中文标签\n",
    "plt.rcParams['axes.unicode_minus']=False \n",
    "\n",
    "FORMAT = 'pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, plot_tree\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "102c0bcb9cfc3be70922d8a308d4e29f02002c3e"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.023628234863281s passed\n"
     ]
    }
   ],
   "source": [
    "data = load_tables('ABC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a40373b87cfcbbfac9be205b3dbacf56bb9bc3d0"
   },
   "source": [
    "# Create Time Series Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pollution_columns(df):\n",
    "    pol_cols = find_pollution_columns(df)\n",
    "    for name, col_name in zip(POLLUTIONS, pol_cols):\n",
    "        df[name] = df[col_name]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "53212882b070962fad91503aec7d2e550ac401c7"
   },
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def create_features(df, label=None):\n",
    "    \"\"\"\n",
    "    Creates time series features from datetime index\n",
    "    \"\"\"\n",
    "    \n",
    "    df['date'] = df.监测时间 if '监测时间' in df.keys() else df.监测日期\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['dayofyear'] = df['date'].dt.dayofyear\n",
    "    df['dayofmonth'] = df['date'].dt.day\n",
    "    df['weekofyear'] = df['date'].dt.weekofyear\n",
    "    _ = POLLUTIONS.copy()\n",
    "    _.remove(label)\n",
    "    X = df[['hour','dayofweek','quarter','month','year',\n",
    "           'dayofyear','dayofmonth','weekofyear'] +\n",
    "            _\n",
    "          ]\n",
    "    if label:\n",
    "        y = df[label]\n",
    "        return X, y\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53212882b070962fad91503aec7d2e550ac401c7"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    result={}\n",
    "    for place in 'ABC':\n",
    "        df = data[place]['1']\n",
    "        preprocess_pollution_columns(df)\n",
    "        split_date = '2021-01-13'\n",
    "        train_data = df.loc[df.监测时间 <= split_date].copy()\n",
    "        test_data = df.loc[df.监测时间 > split_date].copy()\n",
    "\n",
    "\n",
    "        regs = {}\n",
    "        for p in POLLUTIONS:\n",
    "            X_train, y_train = create_features(train_data, label=p)\n",
    "            X_test, y_test = create_features(test_data, label=p)\n",
    "            reg = xgb.XGBRegressor(n_estimators=1000)\n",
    "\n",
    "            reg.fit(X_train, y_train,\n",
    "                eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "                early_stopping_rounds=5000,\n",
    "               verbose=False) # Change verbose to True if you want to see it train\n",
    "\n",
    "            test_data[\"预测的\"+p] = reg.predict(X_test)\n",
    "            all_data = pd.concat([test_data, train_data], sort=False)\n",
    "\n",
    "            _ = all_data[[p,\"预测的\"+p]].plot(figsize=(12, 8))\n",
    "            plt.savefig(f\"results/prob3/预测{place}地_{p[:4]}.\"+FORMAT, format=FORMAT)\n",
    "            # plt.close()\n",
    "            regs[p] = reg\n",
    "        result[place] = regs\n",
    "    return result\n",
    "\n",
    "result = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        SO2        NO2       PM10     PM2.5         O3        CO  AQI 主要污染物\n",
      "0  7.192971  22.578356  31.014568  9.943605  29.479832  0.417040   31  PM10\n",
      "1  7.192971  22.578356  31.014568  9.943605  29.479832  0.437403   31  PM10\n",
      "2  7.192971  22.578356  31.014568  9.943605  29.479832  0.437403   31  PM10\n",
      "        SO2        NO2     PM10      PM2.5         O3        CO  AQI 主要污染物\n",
      "0  5.885881  20.832916  27.0807  11.045207  33.714005  0.362359   27  PM10\n",
      "1  5.885881  23.144234  27.0807  11.045207  33.714005  0.362359   29   NO2\n",
      "2  5.885881  23.144234  27.0807  11.045207  33.714005  0.362359   29   NO2\n",
      "        SO2        NO2       PM10      PM2.5         O3        CO  AQI 主要污染物\n",
      "0  4.666842  26.564758  17.563309  16.126091  32.956848  0.509525   33   NO2\n",
      "1  4.666842  26.564758  17.563309  16.523323  30.636160  0.509525   33   NO2\n",
      "2  4.666842  26.564758  17.563309  16.599525  30.636160  0.509525   33   NO2\n"
     ]
    }
   ],
   "source": [
    "def test(result):\n",
    "    writer = pd.ExcelWriter(\"results/prob3/result.xlsx\", engine='xlsxwriter')\n",
    "    for place in ['A1', 'A2', 'A3']:\n",
    "        data_dict = {}\n",
    "        df = data[place]['2']\n",
    "        df = preprocess_pollution_columns(df)\n",
    "        split_date = '2021-07-13'\n",
    "        test_data = df.loc[df.监测日期 >= split_date].copy()\n",
    "        for p in POLLUTIONS:\n",
    "            X_test, y_test = create_features(test_data, label=p)\n",
    "            reg = result[place][p]\n",
    "            test_data[\"预测的\"+p] = reg.predict(X_test)\n",
    "            data_dict[p] = list(test_data[\"预测的\"+p])\n",
    "            \n",
    "        frame = pd.DataFrame(data=data_dict)\n",
    "        \n",
    "        aqis = []\n",
    "        main_factors = []\n",
    "        for i in range(len(frame)):\n",
    "            polu = list(frame.iloc[i])\n",
    "            polu[-2] *= 4/3 * polu[-2] #考虑二次污染\n",
    "            aqi, main_factor = compute_aqi(*polu, True)\n",
    "            aqis.append(aqi)\n",
    "            main_factors.append(main_factor)\n",
    "        frame['AQI'] = aqis\n",
    "        frame['主要污染物'] = main_factors\n",
    "        \n",
    "        frame.to_excel(writer, sheet_name=place)\n",
    "        print(frame)\n",
    "    writer.save()\n",
    "test(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "60ffc6c21d16280ee05faead916fd09c34fa490c"
   },
   "source": [
    "# Create XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3463148/535962520.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'reg' is not defined"
     ]
    }
   ],
   "source": [
    "_ = plot_importance(reg, height=0.9, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7b0c23f8ab69549bcf64c154a4ab6cb86c0fe204"
   },
   "source": [
    "# Look at first month of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b07c99d3ceffa3634714f23ab3e27b7d1c6fb3e1"
   },
   "outputs": [],
   "source": [
    "# Plot the forecast with the actuals\n",
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(5)\n",
    "f.set_figwidth(15)\n",
    "_ = all_data[[POLLUTIONS1[0],\"预测的\"+POLLUTIONS1[0]]].plot(ax=ax,\n",
    "                                              style=['-','.'])\n",
    "# ax.set_xbound(lower='2021-06-13', upper='2021-07-13')\n",
    "# ax.set_ylim(0, 60000)\n",
    "# plot = plt.suptitle('January 2015 Forecast vs Actuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "153d79e6a408c5705b5c4a19ef100449d0c38d8b"
   },
   "outputs": [],
   "source": [
    "# Plot the forecast with the actuals\n",
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(5)\n",
    "f.set_figwidth(15)\n",
    "_ = all_data[['MW_Prediction','PJME_MW']].plot(ax=ax,\n",
    "                                              style=['-','.'])\n",
    "ax.set_xbound(lower='2021-06-13', upper='2021-07-13')\n",
    "ax.set_ylim(0, 60000)\n",
    "plot = plt.suptitle('First Week of January Forecast vs Actuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8e24f91a3a71acd6d16eb930381d5b9baabffae2"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(5)\n",
    "f.set_figwidth(15)\n",
    "_ = all_data[['MW_Prediction','PJME_MW']].plot(ax=ax,\n",
    "                                              style=['-','.'])\n",
    "ax.set_ylim(0, 60000)\n",
    "ax.set_xbound(lower='07-01-2015', upper='07-08-2015')\n",
    "plot = plt.suptitle('First Week of July Forecast vs Actuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "31964c9653b64c3e3f6fe48f5b3d7eb1987eaf84"
   },
   "source": [
    "# Error Metrics On Test Set\n",
    "Our RMSE error is 13780445  \n",
    "Our MAE error is 2848.89  \n",
    "Our MAPE error is 8.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "baf33e07988ad1860ab3fee31817cba797110879"
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_true=test_data['PJME_MW'],\n",
    "                   y_pred=test_data['MW_Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4943521452099c82efb7fd00da4305b457a52fc0"
   },
   "outputs": [],
   "source": [
    "mean_absolute_error(y_true=test_data['PJME_MW'],\n",
    "                   y_pred=test_data['MW_Prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3bfa58efee593e8ea8a8accdcd981b6b9cde5146"
   },
   "source": [
    "I like using mean absolute percent error because it gives an easy to interperate percentage showing how off the predictions are.\n",
    "MAPE isn't included in sklearn so we need to use a custom function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "32fcb6d7905e2847a18e89e310b0a61bfc6c3321"
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eb095dfe68dccdc10f545d2345e3ed10865102dd"
   },
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(y_true=test_data['PJME_MW'],\n",
    "                   y_pred=test_data['MW_Prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5f5225264a6ae80a24b4c2802eff73f576aa4867"
   },
   "source": [
    "# Look at Worst and Best Predicted Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb1fcc67506951b7a9708cce9463f899b98a7b37"
   },
   "outputs": [],
   "source": [
    "test_data['error'] = test_data['PJME_MW'] - test_data['MW_Prediction']\n",
    "test_data['abs_error'] = test_data['error'].apply(np.abs)\n",
    "error_by_day = test_data.groupby(['year','month','dayofmonth']) \\\n",
    "    .mean()[['PJME_MW','MW_Prediction','error','abs_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6364555e8bed275076f6f6ee93c8537da3741aba"
   },
   "outputs": [],
   "source": [
    "# Over forecasted days\n",
    "error_by_day.sort_values('error', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "adcc6c413889583c4ab195d3b9933827ff630762"
   },
   "source": [
    "Notice anything about the over forecasted days? \n",
    "- #1 worst day - July 4th, 2016 - is a holiday. \n",
    "- #3 worst day - December 25, 2015 - Christmas\n",
    "- #5 worst day - July 4th, 2016 - is a holiday.   \n",
    "Looks like our model may benefit from adding a holiday indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72ee8685aea837bc274cec93c2fabb108b6a107d"
   },
   "outputs": [],
   "source": [
    "# Worst absolute predicted days\n",
    "error_by_day.sort_values('abs_error', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0f4c1097312214cb35781d1e692a50b9a4c75654"
   },
   "source": [
    "The best predicted days seem to be a lot of october (not many holidays and mild weather) Also early may"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "faf0e5530e1f02fb82022813780562c42a911493"
   },
   "outputs": [],
   "source": [
    "# Best predicted days\n",
    "error_by_day.sort_values('abs_error', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0f78f528ca59a1e1cfb253ab69651149a5018b3b"
   },
   "source": [
    "# Plotting some best/worst predicted days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd9d1df9db6153690488549f11cfd32c87cce960"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(5)\n",
    "f.set_figwidth(10)\n",
    "_ = all_data[['MW_Prediction','PJME_MW']].plot(ax=ax,\n",
    "                                              style=['-','.'])\n",
    "ax.set_ylim(0, 60000)\n",
    "ax.set_xbound(lower='08-13-2016', upper='08-14-2016')\n",
    "plot = plt.suptitle('Aug 13, 2016 - Worst Predicted Day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2ca961106be98ebbf703ba52b9d10a2d58ff8a56"
   },
   "source": [
    "This one is pretty impressive. SPOT ON!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39eac1134b1278e7dd5f848ea03e7246d730b97f"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(5)\n",
    "f.set_figwidth(10)\n",
    "_ = all_data[['MW_Prediction','PJME_MW']].plot(ax=ax,\n",
    "                                              style=['-','.'])\n",
    "ax.set_ylim(0, 60000)\n",
    "ax.set_xbound(lower='10-03-2016', upper='10-04-2016')\n",
    "plot = plt.suptitle('Oct 3, 2016 - Best Predicted Day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b20a85a8224428cbcb9888c62fa466757b0e04f7"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(5)\n",
    "f.set_figwidth(10)\n",
    "_ = all_data[['MW_Prediction','PJME_MW']].plot(ax=ax,\n",
    "                                              style=['-','.'])\n",
    "ax.set_ylim(0, 60000)\n",
    "ax.set_xbound(lower='08-13-2016', upper='08-14-2016')\n",
    "plot = plt.suptitle('Aug 13, 2016 - Worst Predicted Day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4cd7f2212c6ca87a2ffb2b8ea12a3581e4ee4027"
   },
   "source": [
    "# Up next?\n",
    "- Add Lag variables\n",
    "- Add holiday indicators.\n",
    "- Add weather data source."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
